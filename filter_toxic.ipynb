{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28610429",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e18a8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pymystem3 import Mystem\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.pipeline import  make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "48305272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mukha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "csv_file = 'with_lemma.csv' #'labeled.csv'\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "m_steam = Mystem()\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords = list(nltk_stopwords.words('russian'))\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07249322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9eda6f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d2caa808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f5f47218",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e6bfd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Отображает гистаграму распределения классов\n",
    "def histogram_show(data, col):\n",
    "    \n",
    "    data[col].hist()\n",
    "    plt.title('Количество комментариев')\n",
    "    plt.xlabel('Значение')\n",
    "    plt.ylabel('Количество')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d39534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram_show(data,'toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36baa023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#отоброжает процентное соотношение классов\n",
    "def precent_show(data):\n",
    "    data.toxic.value_counts(normalize=True).plot(kind='bar')\n",
    "    plt.title('% toxic')\n",
    "    plt.ylabel('%')\n",
    "    plt.xlabel('Классы')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3587ca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#precent_show(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da182280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для лемматизация текста и очистки \n",
    "def lemma_text(text):\n",
    "    lemaized_text = \" \".join(m_steam.lemmatize(text))\n",
    "    cleare_text =  re.sub(r'[^а-яА-ЯёЁ ]', ' ',lemaized_text)\n",
    "    print(cleare_text)\n",
    "    return \" \".join(cleare_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5202e43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['lemma_text'] = data['comment'].apply(lemma_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d859790c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 14404 entries, 0 to 14411\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   comment     14404 non-null  object \n",
      " 1   toxic       14404 non-null  float64\n",
      " 2   lemma_text  14404 non-null  object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 450.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "data['lemma_text'].drop_duplicates(keep='first' , inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936c80be",
   "metadata": {},
   "source": [
    "Разделим данные на бучающию и тестовую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8eed0257",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Разделим данные\n",
    "train_x, test_x , train_y, test_y = train_test_split(data['lemma_text'], data['toxic'], test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "72d464aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mukha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Создадим и обучим модель LogisticRegression с балансировкой весов\n",
    "pipeline = make_pipeline(count_tf_idf,\n",
    "                              LogisticRegression(penalty='l1', solver='saga',class_weight='balanced',max_iter=5000))\n",
    "\n",
    "params={\n",
    "    'logisticregression__C':[4, 10, 2]\n",
    "}\n",
    "\n",
    "gs_lr = GridSearchCV(pipeline,\n",
    "                      params,\n",
    "                      cv=2,\n",
    "                      scoring='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2bf2bc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score 0.8410136237266939\n",
      "Best model parameters Pipeline(steps=[('tfidfvectorizer',\n",
      "                 TfidfVectorizer(stop_words=['и', 'в', 'во', 'не', 'что', 'он',\n",
      "                                             'на', 'я', 'с', 'со', 'как', 'а',\n",
      "                                             'то', 'все', 'она', 'так', 'его',\n",
      "                                             'но', 'да', 'ты', 'к', 'у', 'же',\n",
      "                                             'вы', 'за', 'бы', 'по', 'только',\n",
      "                                             'ее', 'мне', ...])),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=4, class_weight='balanced', max_iter=5000,\n",
      "                                    penalty='l1', solver='saga'))])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "gs_lr.fit(train_x, train_y)\n",
    "print('F1 score', gs_lr.best_score_)\n",
    "print('Best model parameters', gs_lr.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ccc5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09dce42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec06b01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
